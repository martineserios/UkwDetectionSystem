{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLOv5 3: Export to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import glob as glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/martin/Projects/ongoing/ukw/wildfire_detection_system/trained_models/full/yolov5m_v2_optimize/weights/best.pt'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PRETRAINED_MODEL_LOCATION = '/home/martin/Projects/ongoing/ukw/wildfire_detection_system/trained_models/full/yolov5m_v1/weights/best.pt'\n",
    "NEW_PYTORCH_MODEL_LOCATION = '/home/martin/Projects/ongoing/ukw/wildfire_detection_system/trained_models/full/yolov5m_v2_optimize/weights/best.pt'\n",
    "\n",
    "NEW_PYTORCH_MODEL_LOCATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mexport: \u001b[0mdata=yolov5/data/coco128.yaml, weights=['/home/martin/Projects/ongoing/ukw/wildfire_detection_system/trained_models/full/yolov5m_v1/weights/best.pt'], imgsz=[640, 640], batch_size=1, device=cpu, half=False, inplace=False, keras=False, optimize=False, int8=True, per_tensor=True, dynamic=False, simplify=False, opset=17, verbose=False, workspace=4, nms=False, agnostic_nms=False, topk_per_class=100, topk_all=100, iou_thres=0.45, conf_thres=0.25, include=['saved_model']\n",
      "YOLOv5 🚀 v7.0-307-g920c721e Python-3.10.12 torch-2.2.2+cu121 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 212 layers, 20856975 parameters, 0 gradients, 47.9 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from /home/martin/Projects/ongoing/ukw/wildfire_detection_system/trained_models/full/yolov5m_v1/weights/best.pt with output shape (1, 25200, 7) (40.3 MB)\n",
      "2024-05-16 13:50:30.737689: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-16 13:50:30.737773: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-16 13:50:30.737838: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.14.0...\n",
      "WARNING ⚠️ using Tensorflow 2.14.0 > 2.13.1 might cause issue when exporting the model to tflite https://github.com/ultralytics/yolov5/issues/12489\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              \n",
      "  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n",
      "  2                -1  1     65280  models.common.C3                        [96, 96, 2]                   \n",
      "  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n",
      "  4                -1  1    444672  models.common.C3                        [192, 192, 4]                 \n",
      "  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n",
      "  6                -1  1   2512896  models.common.C3                        [384, 384, 6]                 \n",
      "  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n",
      "  8                -1  1   4134912  models.common.C3                        [768, 768, 2]                 \n",
      "  9                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \n",
      " 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1   1182720  models.common.C3                        [768, 384, 2, False]          \n",
      " 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1    296448  models.common.C3                        [384, 192, 2, False]          \n",
      " 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1   1035264  models.common.C3                        [384, 384, 2, False]          \n",
      " 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   4134912  models.common.C3                        [768, 768, 2, False]          \n",
      " 24      [17, 20, 23]  1     28287  models.yolo.Detect                      [2, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [192, 384, 768], [640, 640]]\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(1, 640, 640, 3)]           0         []                            \n",
      "                                                                                                  \n",
      " tf_conv (TFConv)            (1, 320, 320, 48)            5232      ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " tf_conv_1 (TFConv)          (1, 160, 160, 96)            41568     ['tf_conv[0][0]']             \n",
      "                                                                                                  \n",
      " tfc3 (TFC3)                 (1, 160, 160, 96)            64896     ['tf_conv_1[0][0]']           \n",
      "                                                                                                  \n",
      " tf_conv_9 (TFConv)          (1, 80, 80, 192)             166080    ['tfc3[0][0]']                \n",
      "                                                                                                  \n",
      " tfc3_1 (TFC3)               (1, 80, 80, 192)             443520    ['tf_conv_9[0][0]']           \n",
      "                                                                                                  \n",
      " tf_conv_21 (TFConv)         (1, 40, 40, 384)             663936    ['tfc3_1[0][0]']              \n",
      "                                                                                                  \n",
      " tfc3_2 (TFC3)               (1, 40, 40, 384)             2509824   ['tf_conv_21[0][0]']          \n",
      "                                                                                                  \n",
      " tf_conv_37 (TFConv)         (1, 20, 20, 768)             2654976   ['tfc3_2[0][0]']              \n",
      "                                                                                                  \n",
      " tfc3_3 (TFC3)               (1, 20, 20, 768)             4131840   ['tf_conv_37[0][0]']          \n",
      "                                                                                                  \n",
      " tfsppf (TFSPPF)             (1, 20, 20, 768)             1475712   ['tfc3_3[0][0]']              \n",
      "                                                                                                  \n",
      " tf_conv_47 (TFConv)         (1, 20, 20, 384)             295296    ['tfsppf[0][0]']              \n",
      "                                                                                                  \n",
      " tf_upsample (TFUpsample)    (1, 40, 40, 384)             0         ['tf_conv_47[0][0]']          \n",
      "                                                                                                  \n",
      " tf_concat (TFConcat)        (1, 40, 40, 768)             0         ['tf_upsample[0][0]',         \n",
      "                                                                     'tfc3_2[0][0]']              \n",
      "                                                                                                  \n",
      " tfc3_4 (TFC3)               (1, 40, 40, 384)             1181184   ['tf_concat[0][0]']           \n",
      "                                                                                                  \n",
      " tf_conv_55 (TFConv)         (1, 40, 40, 192)             73920     ['tfc3_4[0][0]']              \n",
      "                                                                                                  \n",
      " tf_upsample_1 (TFUpsample)  (1, 80, 80, 192)             0         ['tf_conv_55[0][0]']          \n",
      "                                                                                                  \n",
      " tf_concat_1 (TFConcat)      (1, 80, 80, 384)             0         ['tf_upsample_1[0][0]',       \n",
      "                                                                     'tfc3_1[0][0]']              \n",
      "                                                                                                  \n",
      " tfc3_5 (TFC3)               (1, 80, 80, 192)             295680    ['tf_concat_1[0][0]']         \n",
      "                                                                                                  \n",
      " tf_conv_63 (TFConv)         (1, 40, 40, 192)             331968    ['tfc3_5[0][0]']              \n",
      "                                                                                                  \n",
      " tf_concat_2 (TFConcat)      (1, 40, 40, 384)             0         ['tf_conv_63[0][0]',          \n",
      "                                                                     'tf_conv_55[0][0]']          \n",
      "                                                                                                  \n",
      " tfc3_6 (TFC3)               (1, 40, 40, 384)             1033728   ['tf_concat_2[0][0]']         \n",
      "                                                                                                  \n",
      " tf_conv_71 (TFConv)         (1, 20, 20, 384)             1327488   ['tfc3_6[0][0]']              \n",
      "                                                                                                  \n",
      " tf_concat_3 (TFConcat)      (1, 20, 20, 768)             0         ['tf_conv_71[0][0]',          \n",
      "                                                                     'tf_conv_47[0][0]']          \n",
      "                                                                                                  \n",
      " tfc3_7 (TFC3)               (1, 20, 20, 768)             4131840   ['tf_concat_3[0][0]']         \n",
      "                                                                                                  \n",
      " tf_detect (TFDetect)        ((1, 25200, 7),              28287     ['tfc3_5[0][0]',              \n",
      "                             )                                       'tfc3_6[0][0]',              \n",
      "                                                                     'tfc3_7[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 20856975 (79.56 MB)\n",
      "Trainable params: 0 (0.00 Byte)\n",
      "Non-trainable params: 20856975 (79.56 MB)\n",
      "__________________________________________________________________________________________________\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success ✅ 22.1s, saved as /home/martin/Projects/ongoing/ukw/wildfire_detection_system/trained_models/full/yolov5m_v1/weights/best_saved_model (79.9 MB)\n",
      "\n",
      "Export complete (24.4s)\n",
      "Results saved to \u001b[1m/home/martin/Projects/ongoing/ukw/wildfire_detection_system/trained_models/full/yolov5m_v1/weights\u001b[0m\n",
      "Detect:          python detect.py --weights /home/martin/Projects/ongoing/ukw/wildfire_detection_system/trained_models/full/yolov5m_v1/weights/best_saved_model \n",
      "Validate:        python val.py --weights /home/martin/Projects/ongoing/ukw/wildfire_detection_system/trained_models/full/yolov5m_v1/weights/best_saved_model \n",
      "PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', '/home/martin/Projects/ongoing/ukw/wildfire_detection_system/trained_models/full/yolov5m_v1/weights/best_saved_model')  \n",
      "Visualize:       https://netron.app\n"
     ]
    }
   ],
   "source": [
    "# Clone YOLOV5 Repository\n",
    "if not os.path.exists('yolov5'):\n",
    "    !git clone https://github.com/ultralytics/yolov5.git\n",
    "\n",
    "# Export to onnx\n",
    "!python3 yolov5/export.py --weights {PRETRAINED_MODEL_LOCATION} --int8 --include saved_model --per-tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/martin/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 🚀 2024-5-9 Python-3.10.12 torch-2.2.2+cu121 CPU\n",
      "\n",
      "Loading /home/martin/Projects/ongoing/ukw/wildfire_detection_system/trained_models/full/yolov5m_v1/weights/best_saved_model for TensorFlow SavedModel inference...\n",
      "WARNING:absl:Importing a function (__inference_pruned_9309) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'custom', '/home/martin/Projects/ongoing/ukw/wildfire_detection_system/trained_models/full/yolov5m_v1/weights/best_saved_model') \n",
    "# model = torch.hub.load('ultralytics/yolov5', 'custom', NEW_PYTORCH_MODEL_LOCATION) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_IMAGE_LOCATION = '/home/martin/Projects/ongoing/ukw/data/test_images/test_def.jpeg'\n",
    "# Load test iamge\n",
    "img0 = cv2.imread(TEST_IMAGE_LOCATION)\n",
    "image = cv2.resize(img0, (640, 640))\n",
    "# image_bchw = np.transpose(np.expand_dims(image, 0), (0, 3, 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YOLOv5 <class 'models.common.Detections'> instance\n",
       "image 1/1: 640x640 (no detections)\n",
       "Speed: 5.1ms pre-process, 473.2ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction\n",
    "model(image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
