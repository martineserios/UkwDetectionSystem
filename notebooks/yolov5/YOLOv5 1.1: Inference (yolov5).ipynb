{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "237b90bd",
   "metadata": {},
   "source": [
    "# YOLOv5 1: Inference (YOLOv5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2b9bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob as glob\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb325457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some parameters\n",
    "PRETRAINED_MODEL_LOCATION = '/home/martin/Projects/ongoing/ukw/ukw_detection_system/models/yolov5s/v3_inc_epochs35/weights/best.pt'\n",
    "TEST_IMAGES_LOCATION = '/home/martin/Projects/ongoing/ukw/ukw_detection_system/data/test/imgs_mariano'\n",
    "OUTPUT_FOLDER = '/'.join(PRETRAINED_MODEL_LOCATION.split('/')[:-2]) + \"/test_inferences\"\n",
    "\n",
    "TRAIN = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1f61b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone YOLOV5 Repository\n",
    "if not os.path.exists('yolov5'):\n",
    "    !git clone https://github.com/ultralytics/yolov5.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b2862c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd yolov5/\n",
    "# Helper function to logging results\n",
    "def set_res_dir():\n",
    "    # Directory to store results\n",
    "    res_dir_count = len(glob.glob('runs/train/*'))\n",
    "    print(f\"Current number of result directories: {res_dir_count}\")\n",
    "    if TRAIN:\n",
    "        RES_DIR = f\"results_{res_dir_count+1}\"\n",
    "        print(RES_DIR)\n",
    "    else:\n",
    "        RES_DIR = f\"results_{res_dir_count}\"\n",
    "    return RES_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f74dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert bounding boxes in YOLO format to xmin, ymin, xmax, ymax.\n",
    "def yolo2bbox(bboxes):\n",
    "    xmin, ymin = bboxes[0]-bboxes[2]/2, bboxes[1]-bboxes[3]/2\n",
    "    xmax, ymax = bboxes[0]+bboxes[2]/2, bboxes[1]+bboxes[3]/2\n",
    "    return xmin, ymin, xmax, ymax\n",
    "\n",
    "\n",
    "# Function to draw the boxes\n",
    "def plot_box(image, bboxes, labels):\n",
    "    # Need the image height and width to denormalize\n",
    "    # the bounding box coordinates\n",
    "    h, w, _ = image.shape\n",
    "    for box_num, box in enumerate(bboxes):\n",
    "        x1, y1, x2, y2 = yolo2bbox(box)\n",
    "        # denormalize the coordinates\n",
    "        xmin = int(x1*w)\n",
    "        ymin = int(y1*h)\n",
    "        xmax = int(x2*w)\n",
    "        ymax = int(y2*h)\n",
    "        width = xmax - xmin\n",
    "        height = ymax - ymin\n",
    "\n",
    "        class_name = class_names[int(labels[box_num])]\n",
    "\n",
    "        cv2.rectangle(\n",
    "            image,\n",
    "            (xmin, ymin), (xmax, ymax),\n",
    "            color=colors[class_names.index(class_name)],\n",
    "            thickness=2\n",
    "        )\n",
    "\n",
    "        font_scale = min(1,max(3,int(w/500)))\n",
    "        font_thickness = min(2, max(10,int(w/50)))\n",
    "\n",
    "        p1, p2 = (int(xmin), int(ymin)), (int(xmax), int(ymax))\n",
    "        # Text width and height\n",
    "        tw, th = cv2.getTextSize(\n",
    "            class_name,\n",
    "            0, fontScale=font_scale, thickness=font_thickness\n",
    "        )[0]\n",
    "        p2 = p1[0] + tw, p1[1] + -th - 10\n",
    "        cv2.rectangle(\n",
    "            image,\n",
    "            p1, p2,\n",
    "            color=colors[class_names.index(class_name)],\n",
    "            thickness=-1,\n",
    "        )\n",
    "        cv2.putText(\n",
    "            image,\n",
    "            class_name,\n",
    "            (xmin+1, ymin-10),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            font_scale,\n",
    "            (255, 255, 255),\n",
    "            font_thickness\n",
    "        )\n",
    "    return image\n",
    "\n",
    "\n",
    "# Function to plot images with the bounding boxes.\n",
    "def plot(image_paths, label_paths, num_samples):\n",
    "    all_training_images = glob.glob(image_paths)\n",
    "    all_training_labels = glob.glob(label_paths)\n",
    "    all_training_images.sort()\n",
    "    all_training_labels.sort()\n",
    "\n",
    "    num_images = len(all_training_images)\n",
    "\n",
    "    plt.figure(figsize=(15, 12))\n",
    "    for i in range(num_samples):\n",
    "        j = random.randint(0,num_images-1)\n",
    "        image = cv2.imread(all_training_images[j])\n",
    "        with open(all_training_labels[j], 'r') as f:\n",
    "            bboxes = []\n",
    "            labels = []\n",
    "            label_lines = f.readlines()\n",
    "            for label_line in label_lines:\n",
    "                label = label_line[0]\n",
    "                bbox_string = label_line[2:]\n",
    "                x_c, y_c, w, h = bbox_string.split(' ')\n",
    "                x_c = float(x_c)\n",
    "                y_c = float(y_c)\n",
    "                w = float(w)\n",
    "                h = float(h)\n",
    "                bboxes.append([x_c, y_c, w, h])\n",
    "                labels.append(label)\n",
    "        result_image = plot_box(image, bboxes, labels)\n",
    "        plt.subplot(2, 2, i+1)\n",
    "        plt.imshow(result_image[:, :, ::-1])\n",
    "        plt.axis('off')\n",
    "    plt.subplots_adjust(wspace=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1051c856",
   "metadata": {
    "id": "1051c856"
   },
   "source": [
    "The following functions are for carrying out inference on images and videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082de152",
   "metadata": {
    "id": "082de152"
   },
   "outputs": [],
   "source": [
    "# Helper function for inference on images.\n",
    "def inference(RES_DIR, data_path, weights, output_folder_path):\n",
    "    # Directory to store inference results.\n",
    "    print(f\"Inference detection directories: {output_folder_path}\")\n",
    "    # Inference on images.\n",
    "    !python detect.py --weights {weights} \\\n",
    "    --source {data_path} --name {output_folder_path} --view-img\n",
    "    return output_folder_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d440c92",
   "metadata": {
    "id": "2d440c92"
   },
   "source": [
    "We may also need to visualize images in any of the directories. The following function accepts a directory path and plots all the images in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81a2aaf",
   "metadata": {
    "id": "e81a2aaf"
   },
   "outputs": [],
   "source": [
    "def visualize(INFER_DIR, n_images):\n",
    "    # Visualize inference images.\n",
    "    INFER_PATH = f\"runs/detect/{INFER_DIR}\"\n",
    "    infer_images = glob.glob(f\"{INFER_PATH}/*.jpg\")\n",
    "    print(infer_images)\n",
    "    for pred_image in infer_images[:n_images]:\n",
    "        image = cv2.imread(pred_image)\n",
    "        plt.figure(figsize=(19, 16))\n",
    "        plt.imshow(image[:, :, ::-1])\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8fa70a",
   "metadata": {
    "id": "9a8fa70a"
   },
   "source": [
    "**Visualize validation prediction images.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iS-qNzHR97Ce",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iS-qNzHR97Ce",
    "outputId": "e0ee7b2b-8320-4def-87d2-71df347bf057"
   },
   "outputs": [],
   "source": [
    "# Inference on images.\n",
    "RES_DIR = set_res_dir()\n",
    "\n",
    "image_infer_dir = inference(RES_DIR, TEST_IMAGES_LOCATION, PRETRAINED_MODEL_LOCATION, OUTPUT_FOLDER)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "custom_object_detection_yolov5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
